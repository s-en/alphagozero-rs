{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=DualNet\n",
      "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "  (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "  (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "  (layers): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (2): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "  )\n",
      "  (pi): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "    (2): RecursiveScriptModule(original_name=ReLU)\n",
      "    (3): RecursiveScriptModule(original_name=Flatten)\n",
      "    (4): RecursiveScriptModule(original_name=Linear)\n",
      "    (5): RecursiveScriptModule(original_name=LogSoftmax)\n",
      "  )\n",
      "  (v): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "    (2): RecursiveScriptModule(original_name=ReLU)\n",
      "    (3): RecursiveScriptModule(original_name=Flatten)\n",
      "    (4): RecursiveScriptModule(original_name=Linear)\n",
      "    (5): RecursiveScriptModule(original_name=ReLU)\n",
      "    (6): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.jit.load('7x7/best.pt')\n",
    "# loaded = torch.jit.load('5x5/best.pt')\n",
    "# loaded = torch.jit.load('src/dualnet5x5_v2.pt')\n",
    "# loaded = torch.jit.load('src/dualnet5x5_se.pt')\n",
    "# loaded = torch.jit.load('src/dualnet7x7_se.pt')\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Float(3, 12, 7, 7, strides=[588, 49, 7, 1], requires_grad=0, device=cpu),\n",
      "      %pi.4.bias : Float(50, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.4.weight : Float(50, 1568, strides=[1568, 1], requires_grad=0, device=cuda:0),\n",
      "      %v.4.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.4.weight : Float(32, 147, strides=[147, 1], requires_grad=0, device=cuda:0),\n",
      "      %v.6.bias : Float(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.6.weight : Float(1, 32, strides=[32, 1], requires_grad=0, device=cuda:0),\n",
      "      %95 : Float(32, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %96 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %98 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %99 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %101 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %102 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %104 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %105 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %107 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %108 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %110 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %111 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %113 : Float(32, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %114 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %116 : Float(32, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %117 : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %119 : Float(3, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %120 : Float(3, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %52 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= -1  12   7   7 [ CPULongType{4} ]]()\n",
      "  %53 : Float(3, 12, 7, 7, strides=[588, 49, 7, 1], device=cpu) = onnx::Reshape(%x.1, %52) # dualnet7x7.py:78:0\n",
      "  %94 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%53, %95, %96)\n",
      "  %56 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%94) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %97 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%56, %98, %99)\n",
      "  %59 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%97) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %100 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%59, %101, %102)\n",
      "  %62 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Add(%100, %56) # dualnet7x7.py:33:0\n",
      "  %63 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%62) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %103 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %104, %105)\n",
      "  %66 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%103) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %106 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%66, %107, %108)\n",
      "  %69 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Add(%106, %63) # dualnet7x7.py:33:0\n",
      "  %70 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%69) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %109 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %110, %111)\n",
      "  %73 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%109) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %112 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%73, %113, %114)\n",
      "  %76 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Add(%112, %70) # dualnet7x7.py:33:0\n",
      "  %77 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%76) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %115 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %116, %117)\n",
      "  %80 : Float(3, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%115) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %81 : Float(3, 1568, strides=[1568, 1], device=cpu) = onnx::Flatten[axis=1](%80) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:40:0\n",
      "  %82 : Float(3, 50, strides=[50, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%81, %pi.4.weight, %pi.4.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %83 : Float(3, 50, strides=[50, 1], device=cpu) = onnx::LogSoftmax[axis=1](%82) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1768:0\n",
      "  %84 : Float(3, 50, strides=[50, 1], device=cpu) = onnx::Exp(%83) # dualnet7x7.py:83:0\n",
      "  %118 : Float(3, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %119, %120)\n",
      "  %87 : Float(3, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu) = onnx::Relu(%118) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %88 : Float(3, 147, strides=[147, 1], device=cpu) = onnx::Flatten[axis=1](%87) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:40:0\n",
      "  %89 : Float(3, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%88, %v.4.weight, %v.4.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %90 : Float(3, 32, strides=[32, 1], device=cpu) = onnx::Relu(%89) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %91 : Float(3, 1, strides=[1, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%90, %v.6.weight, %v.6.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %92 : Float(3, 1, strides=[1, 1], device=cpu) = onnx::Tanh(%91) # dualnet7x7.py:84:0\n",
      "  %93 : Float(3, 51, strides=[51, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%84, %92) # dualnet7x7.py:85:0\n",
      "  return (%93)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded.eval()\n",
    "bisze = 7\n",
    "dummy_input = torch.randn((1, 12, bisze, bisze))\n",
    "torch.onnx.export(loaded, dummy_input, \"dualnet.onnx\", example_outputs=torch.rand((1, bisze*bisze+2)), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.autograph.experimental.do_not_convert\n",
    "onnx_model = onnx.load('dualnet.onnx')\n",
    "\n",
    "tf_rep = prepare(onnx_model, device='gpu')\n",
    "tf_rep.export_graph('model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�w�肳�ꂽ�p�X��������܂���B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['x.1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (3, 12, 7, 7)\n",
      "        name: serving_default_x.1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (3, 51)\n",
      "        name: PartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "        Named Argument #1\n",
      "          x.1\n",
      "\n",
      "  Function Name: 'gen_tensor_dict'\n"
     ]
    }
   ],
   "source": [
    "!cd train\n",
    "!saved_model_cli show --dir ./model.pb --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file js_model\\model.json...\n",
      "weight PartitionedCall/onnx_tf_prefix_Constant_0 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/Where with shape (0, 1) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/Cast with shape (1,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/GatherV2 with shape (0,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/zeros with shape () and dtype int64 was auto converted to the type int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 17:13:07.339591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-24 17:13:07.499463: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-01-24 17:13:07.499944: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2022-01-24 17:13:07.587312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
      "2022-01-24 17:13:07.587503: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 278 nodes (251), 267 edges (241), time = 8.646ms.\n",
      "2022-01-24 17:13:07.587698: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.291ms.\n",
      "2022-01-24 17:13:08.482204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
      "2022-01-24 17:13:08.482499: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.012ms.\n",
      "2022-01-24 17:13:08.482738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 224 nodes (-36), 231 edges (-36), time = 3.234ms.\n",
      "2022-01-24 17:13:08.482929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 152 nodes (-72), 155 edges (-76), time = 17.308ms.\n",
      "2022-01-24 17:13:08.483226: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 152 nodes (0), 155 edges (0), time = 3.649ms.\n",
      "2022-01-24 17:13:08.483515: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (-22), 133 edges (-22), time = 2.224ms.\n",
      "2022-01-24 17:13:08.483717: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 130 nodes (0), 133 edges (0), time = 1.135ms.\n",
      "2022-01-24 17:13:08.483904: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 133 edges (0), time = 3.921ms.\n",
      "2022-01-24 17:13:08.484098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 3.615ms.\n",
      "2022-01-24 17:13:08.484415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 1.495ms.\n",
      "2022-01-24 17:13:08.484673: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.148ms.\n",
      "2022-01-24 17:13:08.484915: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 130 nodes (0), 133 edges (0), time = 0.731ms.\n",
      "2022-01-24 17:13:08.485192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 133 edges (0), time = 3.063ms.\n",
      "2022-01-24 17:13:08.485465: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 3.872ms.\n",
      "2022-01-24 17:13:08.485747: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 1.351ms.\n",
      "2022-01-24 17:13:08.486038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 130 nodes (0), 133 edges (0), time = 0.792ms.\n",
      "2022-01-24 17:13:08.486307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 133 edges (0), time = 4.196ms.\n",
      "2022-01-24 17:13:08.486573: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 3.367ms.\n",
      "2022-01-24 17:13:08.486772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 1.527ms.\n",
      "2022-01-24 17:13:09.219357: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
      "2022-01-24 17:13:09.219674: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 130 nodes (0), 133 edges (0), time = 0.534ms.\n",
      "2022-01-24 17:13:09.219961: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 133 edges (0), time = 3.86ms.\n",
      "2022-01-24 17:13:09.220179: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 2.89ms.\n",
      "2022-01-24 17:13:09.220390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 1.112ms.\n",
      "2022-01-24 17:13:09.220597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 130 nodes (0), 133 edges (0), time = 0.547ms.\n",
      "2022-01-24 17:13:09.220819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 133 edges (0), time = 3.304ms.\n",
      "2022-01-24 17:13:09.221068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 2.994ms.\n",
      "2022-01-24 17:13:09.221277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 133 edges (0), time = 1.156ms.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!tensorflowjs_converter --input_format=tf_saved_model --output_node_names='output_0' --saved_model_tags=serve model.pb js_model --quantize_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9bf1f2e6bcf5a5ddc2db4e74af98a8bb6c9f182239da13cf8d6aee21f00f13f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "a9bf1f2e6bcf5a5ddc2db4e74af98a8bb6c9f182239da13cf8d6aee21f00f13f"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
