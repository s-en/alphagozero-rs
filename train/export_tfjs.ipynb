{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=DualNet\n",
      "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "  (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "  (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "  (layers): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (2): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (3): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (4): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (5): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (6): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (7): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "    (8): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "      (downsample): RecursiveScriptModule(original_name=Sequential)\n",
      "    )\n",
      "  )\n",
      "  (pi): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "    (2): RecursiveScriptModule(original_name=ReLU)\n",
      "    (3): RecursiveScriptModule(original_name=Flatten)\n",
      "    (4): RecursiveScriptModule(original_name=Linear)\n",
      "    (5): RecursiveScriptModule(original_name=LogSoftmax)\n",
      "  )\n",
      "  (v): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "    (2): RecursiveScriptModule(original_name=ReLU)\n",
      "    (3): RecursiveScriptModule(original_name=Flatten)\n",
      "    (4): RecursiveScriptModule(original_name=Linear)\n",
      "    (5): RecursiveScriptModule(original_name=ReLU)\n",
      "    (6): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.jit.load('7x7/best.pt')\n",
    "# loaded = torch.jit.load('5x5/best.pt')\n",
    "# loaded = torch.jit.load('src/dualnet5x5_v2.pt')\n",
    "# loaded = torch.jit.load('src/dualnet5x5_se.pt')\n",
    "# loaded = torch.jit.load('src/dualnet7x7_se.pt')\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Float(8, 12, 7, 7, strides=[588, 49, 7, 1], requires_grad=0, device=cuda:0),\n",
      "      %conv1.weight : Float(64, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.0.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.1.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.2.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.3.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.4.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.5.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.6.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.7.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.conv1.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn1.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn1.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn2.bias : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layers.8.bn2.weight : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.0.weight : Float(32, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %pi.1.running_var : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.1.running_mean : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.1.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.1.weight : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.4.bias : Float(50, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %pi.4.weight : Float(50, 1568, strides=[1568, 1], requires_grad=0, device=cuda:0),\n",
      "      %v.0.weight : Float(3, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %v.1.running_var : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.1.running_mean : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.1.bias : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.1.weight : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.4.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.4.weight : Float(32, 147, strides=[147, 1], requires_grad=0, device=cuda:0),\n",
      "      %v.6.bias : Float(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %v.6.weight : Float(1, 32, strides=[32, 1], requires_grad=0, device=cuda:0)):\n",
      "  %112 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= -1  12   7   7 [ CPULongType{4} ]]() # dualnet7x7.py:78:0\n",
      "  %input : Float(8, 12, 7, 7, strides=[588, 49, 7, 1], device=cpu) = onnx::Reshape(%x.1, %112) # dualnet7x7.py:78:0\n",
      "  %input0 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.3 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %116 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %117 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-128 : Tensor, %batch_norm_dead_output-129 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input0, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %120 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.3) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.7 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%120, %layers.0.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.11 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %123 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %124 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-135 : Tensor, %batch_norm_dead_output-136 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.7, %layers.0.bn1.weight, %layers.0.bn1.bias, %layers.0.bn1.running_mean, %layers.0.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %127 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.11) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.15 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%127, %layers.0.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %130 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %131 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-142 : Tensor, %batch_norm_dead_output-143 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.15, %layers.0.bn2.weight, %layers.0.bn2.bias, %layers.0.bn2.running_mean, %layers.0.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %134 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out, %120) # dualnet7x7.py:33:0\n",
      "  %135 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%134) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.19 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%135, %layers.1.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.23 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %138 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %139 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-150 : Tensor, %batch_norm_dead_output-151 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.19, %layers.1.bn1.weight, %layers.1.bn1.bias, %layers.1.bn1.running_mean, %layers.1.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %142 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.23) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.27 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%142, %layers.1.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.3 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %145 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %146 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-157 : Tensor, %batch_norm_dead_output-158 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.27, %layers.1.bn2.weight, %layers.1.bn2.bias, %layers.1.bn2.running_mean, %layers.1.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %149 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.3, %135) # dualnet7x7.py:33:0\n",
      "  %150 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%149) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.31 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%150, %layers.2.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.35 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %153 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %154 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-165 : Tensor, %batch_norm_dead_output-166 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.31, %layers.2.bn1.weight, %layers.2.bn1.bias, %layers.2.bn1.running_mean, %layers.2.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %157 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.35) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.39 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%157, %layers.2.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.7 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %160 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %161 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-172 : Tensor, %batch_norm_dead_output-173 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.39, %layers.2.bn2.weight, %layers.2.bn2.bias, %layers.2.bn2.running_mean, %layers.2.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %164 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.7, %150) # dualnet7x7.py:33:0\n",
      "  %165 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%164) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.43 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %layers.3.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.47 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %168 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %169 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-180 : Tensor, %batch_norm_dead_output-181 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.43, %layers.3.bn1.weight, %layers.3.bn1.bias, %layers.3.bn1.running_mean, %layers.3.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %172 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.47) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.51 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%172, %layers.3.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.11 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %175 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %176 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-187 : Tensor, %batch_norm_dead_output-188 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.51, %layers.3.bn2.weight, %layers.3.bn2.bias, %layers.3.bn2.running_mean, %layers.3.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %179 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.11, %165) # dualnet7x7.py:33:0\n",
      "  %180 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%179) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.55 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%180, %layers.4.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.59 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %183 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %184 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-195 : Tensor, %batch_norm_dead_output-196 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.55, %layers.4.bn1.weight, %layers.4.bn1.bias, %layers.4.bn1.running_mean, %layers.4.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %187 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.59) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.63 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%187, %layers.4.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.15 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %190 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %191 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-202 : Tensor, %batch_norm_dead_output-203 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.63, %layers.4.bn2.weight, %layers.4.bn2.bias, %layers.4.bn2.running_mean, %layers.4.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %194 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.15, %180) # dualnet7x7.py:33:0\n",
      "  %195 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%194) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.67 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%195, %layers.5.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.71 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %198 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %199 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-210 : Tensor, %batch_norm_dead_output-211 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.67, %layers.5.bn1.weight, %layers.5.bn1.bias, %layers.5.bn1.running_mean, %layers.5.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %202 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.71) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.75 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %layers.5.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.19 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %205 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %206 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-217 : Tensor, %batch_norm_dead_output-218 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.75, %layers.5.bn2.weight, %layers.5.bn2.bias, %layers.5.bn2.running_mean, %layers.5.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %209 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.19, %195) # dualnet7x7.py:33:0\n",
      "  %210 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%209) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.79 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%210, %layers.6.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.83 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %213 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %214 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-225 : Tensor, %batch_norm_dead_output-226 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.79, %layers.6.bn1.weight, %layers.6.bn1.bias, %layers.6.bn1.running_mean, %layers.6.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %217 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.83) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.87 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%217, %layers.6.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.23 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %220 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %221 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-232 : Tensor, %batch_norm_dead_output-233 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.87, %layers.6.bn2.weight, %layers.6.bn2.bias, %layers.6.bn2.running_mean, %layers.6.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %224 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.23, %210) # dualnet7x7.py:33:0\n",
      "  %225 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%224) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.91 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%225, %layers.7.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.95 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %228 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %229 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-240 : Tensor, %batch_norm_dead_output-241 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.91, %layers.7.bn1.weight, %layers.7.bn1.bias, %layers.7.bn1.running_mean, %layers.7.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %232 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.95) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.99 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %layers.7.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.27 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %235 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %236 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-247 : Tensor, %batch_norm_dead_output-248 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.99, %layers.7.bn2.weight, %layers.7.bn2.bias, %layers.7.bn2.running_mean, %layers.7.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %239 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.27, %225) # dualnet7x7.py:33:0\n",
      "  %240 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%239) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.103 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%240, %layers.8.conv1.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.107 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %243 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %244 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-255 : Tensor, %batch_norm_dead_output-256 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.103, %layers.8.bn1.weight, %layers.8.bn1.bias, %layers.8.bn1.running_mean, %layers.8.bn1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %247 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%input.107) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.111 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%247, %layers.8.conv2.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %out.31 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu), %250 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %251 : Float(64, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-262 : Tensor, %batch_norm_dead_output-263 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.111, %layers.8.bn2.weight, %layers.8.bn2.bias, %layers.8.bn2.running_mean, %layers.8.bn2.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %254 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Add(%out.31, %240) # dualnet7x7.py:33:0\n",
      "  %255 : Float(8, 64, 7, 7, strides=[3136, 49, 7, 1], device=cpu) = onnx::Relu(%254) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %input.115 : Float(8, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%255, %pi.0.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.119 : Float(8, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu), %258 : Float(32, strides=[1], requires_grad=0, device=cuda:0), %259 : Float(32, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-270 : Tensor, %batch_norm_dead_output-271 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.115, %pi.1.weight, %pi.1.bias, %pi.1.running_mean, %pi.1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %262 : Float(8, 32, 7, 7, strides=[1568, 49, 7, 1], device=cpu) = onnx::Relu(%input.119) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %263 : Float(8, 1568, strides=[1568, 1], device=cpu) = onnx::Flatten[axis=1](%262) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:40:0\n",
      "  %input.123 : Float(8, 50, strides=[50, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%263, %pi.4.weight, %pi.4.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %265 : Float(8, 50, strides=[50, 1], device=cpu) = onnx::LogSoftmax[axis=1](%input.123) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1768:0\n",
      "  %pi : Float(8, 50, strides=[50, 1], device=cpu) = onnx::Exp(%265) # dualnet7x7.py:83:0\n",
      "  %input.127 : Float(8, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%255, %v.0.weight) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:439:0\n",
      "  %input.131 : Float(8, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu), %269 : Float(3, strides=[1], requires_grad=0, device=cuda:0), %270 : Float(3, strides=[1], requires_grad=0, device=cuda:0), %batch_norm_dead_output-284 : Tensor, %batch_norm_dead_output-285 : Tensor = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%input.127, %v.1.weight, %v.1.bias, %v.1.running_mean, %v.1.running_var) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2281:0\n",
      "  %273 : Float(8, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu) = onnx::Relu(%input.131) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %274 : Float(8, 147, strides=[147, 1], device=cpu) = onnx::Flatten[axis=1](%273) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:40:0\n",
      "  %input.135 : Float(8, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%274, %v.4.weight, %v.4.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %276 : Float(8, 32, strides=[32, 1], device=cpu) = onnx::Relu(%input.135) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1296:0\n",
      "  %277 : Float(8, 1, strides=[1, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%276, %v.6.weight, %v.6.bias) # C:\\Users\\sen\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %v : Float(8, 1, strides=[1, 1], device=cpu) = onnx::Tanh(%277) # dualnet7x7.py:84:0\n",
      "  %279 : Float(8, 51, strides=[51, 1], requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%pi, %v) # dualnet7x7.py:85:0\n",
      "  return (%279)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded.eval()\n",
    "bisze = 7\n",
    "dummy_input = torch.randn((8, 12, bisze, bisze)).to(\"cuda:0\")\n",
    "torch.onnx.export(loaded, dummy_input, \"dualnet.onnx\", do_constant_folding=True, export_params=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `__call__` contains input name(s) x.1 with unsupported characters which will be renamed to x_1 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "# from onnx_tf.backend import prepare\n",
    "\n",
    "# # tf.autograph.experimental.do_not_convert\n",
    "# onnx_model = onnx.load('dualnet.onnx')\n",
    "# tf_rep = prepare(onnx_model, device='gpu')\n",
    "# tf_rep.export_graph('model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!onnx-tf convert -i dualnet.onnx -o onnxout\n",
    "!tensorflowjs_converter --input_format=tf_saved_model --output_node_names='output_0' --saved_model_tags=serve onnxout js_model --quantize_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The original model opset version is 9, which does not support quantization. Please update the model to opset >= 11. Updating the model automatically to opset 11. Please verify the quantized model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'dualnet.onnx'\n",
    "model_quant = 'quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 65001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "'saved_model_cli' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !chcp 65001\n",
    "# !cd train\n",
    "# !saved_model_cli show --dir ./model.pb --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\sen\\anaconda3\\envs\\az\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 28, in <module>\n",
      "    import h5py\n",
      "ModuleNotFoundError: No module named 'h5py'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !tensorflowjs_converter --input_format=tf_saved_model --output_node_names='output_0' --saved_model_tags=serve model.pb js_model --quantize_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.saved_model.load('onnxout.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:onnx2keras:Trying to convert multi-output node\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected `name` argument to be a string, but got: ['input.3', '116', '117', 'batch_norm_dead_output-128', 'batch_norm_dead_output-129']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sen\\Documents\\GitHub\\alphagozero-rs\\train\\export_tfjs.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sen/Documents/GitHub/alphagozero-rs/train/export_tfjs.ipynb#ch0000012?line=4'>5</a>\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mdualnet.onnx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sen/Documents/GitHub/alphagozero-rs/train/export_tfjs.ipynb#ch0000012?line=6'>7</a>\u001b[0m \u001b[39m# Call the converter (input - is the main model input name, can be different for your model)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sen/Documents/GitHub/alphagozero-rs/train/export_tfjs.ipynb#ch0000012?line=7'>8</a>\u001b[0m k_model \u001b[39m=\u001b[39m onnx_to_keras(onnx_model, [\u001b[39m'\u001b[39;49m\u001b[39mx.1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\onnx2keras\\converter.py:175\u001b[0m, in \u001b[0;36monnx_to_keras\u001b[1;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=171'>172</a>\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39m... found all, continue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=173'>174</a>\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mset_image_data_format(\u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=174'>175</a>\u001b[0m AVAILABLE_CONVERTERS[node_type](\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=175'>176</a>\u001b[0m     node,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=176'>177</a>\u001b[0m     node_params,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=177'>178</a>\u001b[0m     layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=178'>179</a>\u001b[0m     lambda_funcs,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=179'>180</a>\u001b[0m     node_name,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=180'>181</a>\u001b[0m     keras_names\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=181'>182</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=182'>183</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(keras_names, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/converter.py?line=183'>184</a>\u001b[0m     keras_names \u001b[39m=\u001b[39m keras_names[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\onnx2keras\\normalization_layers.py:48\u001b[0m, in \u001b[0;36mconvert_batchnorm\u001b[1;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=40'>41</a>\u001b[0m     bn \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization(\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=41'>42</a>\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, momentum\u001b[39m=\u001b[39mmomentum, epsilon\u001b[39m=\u001b[39meps,\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=42'>43</a>\u001b[0m         center\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, scale\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=43'>44</a>\u001b[0m         weights\u001b[39m=\u001b[39mweights,\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=44'>45</a>\u001b[0m         name\u001b[39m=\u001b[39mkeras_name\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=45'>46</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=46'>47</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=47'>48</a>\u001b[0m     bn \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mBatchNormalization(\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=48'>49</a>\u001b[0m         axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, momentum\u001b[39m=\u001b[39;49mmomentum, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=49'>50</a>\u001b[0m         weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=50'>51</a>\u001b[0m         name\u001b[39m=\u001b[39;49mkeras_name\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=51'>52</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/onnx2keras/normalization_layers.py?line=53'>54</a>\u001b[0m layers[node_name] \u001b[39m=\u001b[39m bn(input_0)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:1251\u001b[0m, in \u001b[0;36mBatchNormalization.__init__\u001b[1;34m(self, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1235'>1236</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1236'>1237</a>\u001b[0m              axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1237'>1238</a>\u001b[0m              momentum\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1248'>1249</a>\u001b[0m              gamma_constraint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1249'>1250</a>\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1250'>1251</a>\u001b[0m   \u001b[39msuper\u001b[39;49m(BatchNormalization, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1251'>1252</a>\u001b[0m       axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1252'>1253</a>\u001b[0m       momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1253'>1254</a>\u001b[0m       epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1254'>1255</a>\u001b[0m       center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1255'>1256</a>\u001b[0m       scale\u001b[39m=\u001b[39;49mscale,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1256'>1257</a>\u001b[0m       beta_initializer\u001b[39m=\u001b[39;49mbeta_initializer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1257'>1258</a>\u001b[0m       gamma_initializer\u001b[39m=\u001b[39;49mgamma_initializer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1258'>1259</a>\u001b[0m       moving_mean_initializer\u001b[39m=\u001b[39;49mmoving_mean_initializer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1259'>1260</a>\u001b[0m       moving_variance_initializer\u001b[39m=\u001b[39;49mmoving_variance_initializer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1260'>1261</a>\u001b[0m       beta_regularizer\u001b[39m=\u001b[39;49mbeta_regularizer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1261'>1262</a>\u001b[0m       gamma_regularizer\u001b[39m=\u001b[39;49mgamma_regularizer,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1262'>1263</a>\u001b[0m       beta_constraint\u001b[39m=\u001b[39;49mbeta_constraint,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1263'>1264</a>\u001b[0m       gamma_constraint\u001b[39m=\u001b[39;49mgamma_constraint,\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=1264'>1265</a>\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:173\u001b[0m, in \u001b[0;36mBatchNormalizationBase.__init__\u001b[1;34m(self, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, renorm, renorm_clipping, renorm_momentum, fused, trainable, virtual_batch_size, adjustment, name, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=149'>150</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=150'>151</a>\u001b[0m              axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=151'>152</a>\u001b[0m              momentum\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=170'>171</a>\u001b[0m              name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=171'>172</a>\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=172'>173</a>\u001b[0m   \u001b[39msuper\u001b[39;49m(BatchNormalizationBase, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name\u001b[39m=\u001b[39;49mname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=173'>174</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(axis, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m axis[:]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/training/tracking/base.py?line=626'>627</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/training/tracking/base.py?line=627'>628</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/sen/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/training/tracking/base.py?line=628'>629</a>\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/training/tracking/base.py?line=629'>630</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/AppData/Roaming/Python/Python38/site-packages/tensorflow/python/training/tracking/base.py?line=630'>631</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\keras\\engine\\base_layer.py:376\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=370'>371</a>\u001b[0m \u001b[39m# `Layer.compute_mask` will be called at the end of `Layer.__call__` if\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=371'>372</a>\u001b[0m \u001b[39m# `Layer.compute_mask` is overridden, or if the `Layer` subclass sets\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=372'>373</a>\u001b[0m \u001b[39m# `self.supports_masking=True`.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=373'>374</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supports_masking \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m generic_utils\u001b[39m.\u001b[39mis_default(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_mask)\n\u001b[1;32m--> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=375'>376</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_set_name(name)\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=376'>377</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer \u001b[39m=\u001b[39m regularizers\u001b[39m.\u001b[39mget(\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=377'>378</a>\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mactivity_regularizer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=378'>379</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_create_attribute(\u001b[39m'\u001b[39m\u001b[39m_trainable_weights\u001b[39m\u001b[39m'\u001b[39m, [])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\az\\lib\\site-packages\\keras\\engine\\base_layer.py:2513\u001b[0m, in \u001b[0;36mLayer._init_set_name\u001b[1;34m(self, name, zero_based)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=2510'>2511</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=2511'>2512</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=2512'>2513</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/sen/anaconda3/envs/az/lib/site-packages/keras/engine/base_layer.py?line=2513'>2514</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExpected `name` argument to be a string, but got: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected `name` argument to be a string, but got: ['input.3', '116', '117', 'batch_norm_dead_output-128', 'batch_norm_dead_output-129']"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx2keras import onnx_to_keras\n",
    "\n",
    "# Load ONNX model\n",
    "onnx_model = onnx.load('dualnet.onnx')\n",
    "\n",
    "# Call the converter (input - is the main model input name, can be different for your model)\n",
    "k_model = onnx_to_keras(onnx_model, ['x.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9bf1f2e6bcf5a5ddc2db4e74af98a8bb6c9f182239da13cf8d6aee21f00f13f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "a9bf1f2e6bcf5a5ddc2db4e74af98a8bb6c9f182239da13cf8d6aee21f00f13f"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
